{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tamil256NN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO2TLqcKf7xBRlp8xYApV9s"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "37XMOSAOU4ug",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d131fe34-dd25-4cc0-974a-e90021d91c06"
      },
      "source": [
        "import numpy as np\n",
        "%tensorflow_version 1.x\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "import nltk\n",
        "import re\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, LSTM, Bidirectional, Embedding, Dropout\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPE3NXeSVtmj"
      },
      "source": [
        "import pandas as pd\n",
        "def load_dataset(filename):\n",
        "  df = pd.read_csv(filename, encoding = \"utf-8\",\n",
        "       names = [\"Sentence\", \"Intent\"])\n",
        "  intent = df[\"Intent\"]\n",
        "  unique_intent = list(set(intent))\n",
        "  sentences = list(df[\"Sentence\"])\n",
        "  \n",
        "  return (intent, unique_intent, sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGqqZ3l4WF5O"
      },
      "source": [
        "intent, unique_intent, sentences = load_dataset(\"/content/bank.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4YnnZ6IWhvK",
        "outputId": "e7547106-5309-44eb-9383-161227f76264",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        }
      },
      "source": [
        "print(intent[:5])\n",
        "import seaborn as sns\n",
        "sns.countplot(intent,label=\"Count\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    2in1_acoount_info\n",
            "1    2in1_acoount_info\n",
            "2    2in1_acoount_info\n",
            "3    2in1_acoount_info\n",
            "4    2in1_acoount_info\n",
            "Name: Intent, dtype: object\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufy7zZXWWyjJ",
        "outputId": "9159a2c1-90ad-4618-edae-a5d386e344db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "nltk.download(\"punkt\")\n",
        "def cleaning(sentences):\n",
        "  words = [] \n",
        "  for s in sentences:\n",
        "    w = word_tokenize(s)\n",
        "    words.append([i for i in w])     \n",
        "  return words  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8N4GXnqYKcy",
        "outputId": "146cb53a-4563-4b88-a302-2e50f0584284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "cleaned_words = cleaning(sentences)\n",
        "print(len(cleaned_words))\n",
        "print(cleaned_words[:2])  \n",
        "print(len(sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1567\n",
            "[['நான்', '2in1', 'கணக்கில்', 'சேமிப்பது', 'எப்படி', '?'], ['2in1', 'கணக்கில்', 'நான்', 'சேமிப்பது', 'எப்படி', '?']]\n",
            "1567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwgeL5dWcwLI"
      },
      "source": [
        "def create_tokenizer(words, filters = '!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~'):\n",
        "  token = Tokenizer(filters = filters)\n",
        "  token.fit_on_texts(words)\n",
        "  return token"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yJr6j3zc2NH"
      },
      "source": [
        "def max_length(words):\n",
        "  return(len(max(words, key = len)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGFv3Wz1c3h8",
        "outputId": "f9c30c66-8d98-42bb-dac3-60e1e74fbc7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word_tokenizer = create_tokenizer(cleaned_words)\n",
        "vocab_size = len(word_tokenizer.word_index) + 1\n",
        "max_length = max_length(cleaned_words)\n",
        "\n",
        "print(\"Vocab Size = %d and Maximum length = %d\" % (vocab_size, max_length))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab Size = 1141 and Maximum length = 22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkLPLsZudGFP"
      },
      "source": [
        "def encoding_doc(token, words):\n",
        "  return(token.texts_to_sequences(words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUFlvGmBdW_7"
      },
      "source": [
        "encoded_doc = encoding_doc(word_tokenizer, cleaned_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMhHK_fAdbEJ"
      },
      "source": [
        "def padding_doc(encoded_doc, max_length):\n",
        "  return(pad_sequences(encoded_doc, maxlen = max_length, padding = \"post\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nztJIy7vdceo"
      },
      "source": [
        "padded_doc = padding_doc(encoded_doc, max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96UW6oSQdh4Q",
        "outputId": "30dc679a-c3b0-40e4-d9a0-7e52241a0c3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "padded_doc[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  3,  45,  62, 348,  11,   1,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 45,  62,   3, 348,  11,   1,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 11,   3,  45,  62, 348,   1,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [  3,  11,  45,  62, 348,   1,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       [ 45,  62,   3, 587, 287,   2,   1,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c7J1AK8dozB",
        "outputId": "407e33c2-534a-48c0-a9be-0cc01293c5b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Shape of padded docs = \",padded_doc.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of padded docs =  (1567, 22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTIwsFBqeHPE"
      },
      "source": [
        "#tokenizer with filter changed\n",
        "output_tokenizer = create_tokenizer(unique_intent, filters = '!\"#$%&()*+,-/:;<=>?@[\\]^`{|}~')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr1LmLrWeLnz",
        "outputId": "41082805-b8e8-4181-f4ab-20258c609f61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "output_tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'2in1_acoount_info': 14,\n",
              " '2in1_atm_card': 43,\n",
              " '2in1_interest_receiving': 52,\n",
              " '2in1_min_balance': 47,\n",
              " '2in1_pass_book': 33,\n",
              " 'account_currency': 1,\n",
              " 'bank_statement_online': 46,\n",
              " 'cancel_card': 15,\n",
              " 'card_automatic_renewal': 37,\n",
              " 'card_foreign_use': 22,\n",
              " 'card_machine_repair': 5,\n",
              " 'card_usage': 32,\n",
              " 'change_details': 54,\n",
              " 'cvv_use': 27,\n",
              " 'debit_card_requirement': 38,\n",
              " 'fcaispe_required_docs': 35,\n",
              " 'foreign_account_lkr_withdrawal': 28,\n",
              " 'foreign_currency_withdrawal': 50,\n",
              " 'foreign_currency_withdrawal_currency': 44,\n",
              " 'foreign_deposit_loan': 4,\n",
              " 'get_lc_form': 9,\n",
              " 'get_monthly_report': 30,\n",
              " 'housing_loan_documents': 19,\n",
              " 'housing_loan_purpose': 6,\n",
              " 'interest_credit_info': 11,\n",
              " 'internet_bank_loan_amount': 13,\n",
              " 'joint_account_details': 49,\n",
              " 'life_insurance_limit': 18,\n",
              " 'loan_requirement': 56,\n",
              " 'marriage_claim': 40,\n",
              " 'new_card_reader_cost': 31,\n",
              " 'new_saving_book': 10,\n",
              " 'nrfc_account_opening': 23,\n",
              " 'nrfc_info': 20,\n",
              " 'precashing_foreign_fixed_deposit': 24,\n",
              " 'repos_benefits': 41,\n",
              " 'resident_foreign_account_info': 39,\n",
              " 'saving_atmcard_available': 53,\n",
              " 'selan_sure_info': 34,\n",
              " 'seylan_tikiri_minimum_deposit': 36,\n",
              " 'sl_development_bond_benefits': 45,\n",
              " 'slbfe_info': 8,\n",
              " 'suspious_activity': 17,\n",
              " 'tikiri_gift_voucher_age_limit': 16,\n",
              " 'tikiri_gift_voucher_buying_info': 48,\n",
              " 'tikiri_gift_voucher_info': 51,\n",
              " 'tikiri_gift_voucher_min_amount': 2,\n",
              " 'tikiri_gift_voucher_per_person': 21,\n",
              " 'tikiri_gift_voucher_redeem': 55,\n",
              " 'tikiri_gift_voucher_validity': 42,\n",
              " 'tikiri_gift_voucher_withdrawal': 7,\n",
              " 'tikiri_required_docs': 25,\n",
              " 'treasury_bond_advantage': 26,\n",
              " 'treasury_bond_important_features': 29,\n",
              " 'treasury_bond_information': 3,\n",
              " 'update_personal_details': 12}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnAAOGnueWk8"
      },
      "source": [
        "encoded_output = encoding_doc(output_tokenizer, intent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6ZTSOXbeaU-"
      },
      "source": [
        "encoded_output = np.array(encoded_output).reshape(len(encoded_output), 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO3baU22ehDd",
        "outputId": "64832d1b-fd79-44d2-c28e-2445611db3cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "encoded_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1567, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQKN1NG9ekZX"
      },
      "source": [
        "def one_hot(encode):\n",
        "  o = OneHotEncoder(sparse = False)\n",
        "  return(o.fit_transform(encode))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J_Rnp9neovf"
      },
      "source": [
        "output_one_hot = one_hot(encoded_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POdbSVHyerrC",
        "outputId": "946d1704-ec4a-43f3-8b44-09b723c50f91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output_one_hot.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1567, 56)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHYO6k-1evbX"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwgQclLNewsZ"
      },
      "source": [
        "train_X, val_X, train_Y, val_Y = train_test_split(padded_doc, output_one_hot, shuffle = True, test_size = 0.2)\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(train_X, train_Y, shuffle = True, test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovNmNRFhe0o6",
        "outputId": "0afc8f6e-b2a9-49b4-c99c-e3118e020628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"Shape of train_X = %s and train_Y = %s\" % (train_X.shape, train_Y.shape))\n",
        "print(\"Shape of val_X = %s and val_Y = %s\" % (val_X.shape, val_Y.shape))\n",
        "print(\"Shape of test_X = %s and test_Y = %s\" % (val_X.shape, val_Y.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of train_X = (1002, 22) and train_Y = (1002, 56)\n",
            "Shape of val_X = (314, 22) and val_Y = (314, 56)\n",
            "Shape of test_X = (314, 22) and test_Y = (314, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSRLYP3qe56h"
      },
      "source": [
        "def create_model(vocab_size, max_length):\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size, 300, input_length = max_length, trainable = False))\n",
        "  model.add(Bidirectional(LSTM(256)))\n",
        "#   model.add(LSTM(128))\n",
        "  model.add(Dense(32, activation = \"relu\"))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(56, activation = \"softmax\"))\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDbMkC6pe_5J",
        "outputId": "c749dcb0-d186-405c-ea40-d0091da35921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model = create_model(vocab_size, max_length)\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 22, 300)           342300    \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 512)               1140736   \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                16416     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 56)                1848      \n",
            "=================================================================\n",
            "Total params: 1,501,300\n",
            "Trainable params: 1,159,000\n",
            "Non-trainable params: 342,300\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZaglVqnfGtp",
        "outputId": "259ca233-1d58-4b51-99b5-9e2a8e909e57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "filename = 'model.h5'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "hist = model.fit(train_X, train_Y, epochs = 100, batch_size = 32, validation_data = (val_X, val_Y), callbacks = [checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1002 samples, validate on 314 samples\n",
            "Epoch 1/100\n",
            "1002/1002 [==============================] - 10s 10ms/step - loss: 3.9901 - acc: 0.0569 - val_loss: 3.9352 - val_acc: 0.0860\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.93522, saving model to model.h5\n",
            "Epoch 2/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 3.8271 - acc: 0.0858 - val_loss: 3.7738 - val_acc: 0.0828\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.93522 to 3.77376, saving model to model.h5\n",
            "Epoch 3/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 3.6154 - acc: 0.1277 - val_loss: 3.3568 - val_acc: 0.1306\n",
            "\n",
            "Epoch 00003: val_loss improved from 3.77376 to 3.35677, saving model to model.h5\n",
            "Epoch 4/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 3.2906 - acc: 0.1627 - val_loss: 3.1407 - val_acc: 0.1911\n",
            "\n",
            "Epoch 00004: val_loss improved from 3.35677 to 3.14066, saving model to model.h5\n",
            "Epoch 5/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 3.0806 - acc: 0.1956 - val_loss: 2.8731 - val_acc: 0.2389\n",
            "\n",
            "Epoch 00005: val_loss improved from 3.14066 to 2.87307, saving model to model.h5\n",
            "Epoch 6/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 2.8443 - acc: 0.2405 - val_loss: 2.6300 - val_acc: 0.3344\n",
            "\n",
            "Epoch 00006: val_loss improved from 2.87307 to 2.63001, saving model to model.h5\n",
            "Epoch 7/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 2.7860 - acc: 0.2784 - val_loss: 2.7655 - val_acc: 0.3758\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 2.63001\n",
            "Epoch 8/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 2.6497 - acc: 0.2934 - val_loss: 2.4303 - val_acc: 0.4554\n",
            "\n",
            "Epoch 00008: val_loss improved from 2.63001 to 2.43028, saving model to model.h5\n",
            "Epoch 9/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 2.4612 - acc: 0.3403 - val_loss: 2.2376 - val_acc: 0.4809\n",
            "\n",
            "Epoch 00009: val_loss improved from 2.43028 to 2.23759, saving model to model.h5\n",
            "Epoch 10/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 2.2797 - acc: 0.3623 - val_loss: 2.0674 - val_acc: 0.5000\n",
            "\n",
            "Epoch 00010: val_loss improved from 2.23759 to 2.06744, saving model to model.h5\n",
            "Epoch 11/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 2.1477 - acc: 0.4152 - val_loss: 1.9565 - val_acc: 0.5382\n",
            "\n",
            "Epoch 00011: val_loss improved from 2.06744 to 1.95654, saving model to model.h5\n",
            "Epoch 12/100\n",
            "1002/1002 [==============================] - 7s 7ms/step - loss: 2.0257 - acc: 0.4371 - val_loss: 1.8380 - val_acc: 0.5478\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.95654 to 1.83801, saving model to model.h5\n",
            "Epoch 13/100\n",
            "1002/1002 [==============================] - 7s 7ms/step - loss: 1.9071 - acc: 0.4641 - val_loss: 1.7399 - val_acc: 0.5701\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.83801 to 1.73988, saving model to model.h5\n",
            "Epoch 14/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 1.7978 - acc: 0.4940 - val_loss: 1.5823 - val_acc: 0.6083\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.73988 to 1.58233, saving model to model.h5\n",
            "Epoch 15/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 1.7077 - acc: 0.5170 - val_loss: 1.6263 - val_acc: 0.6178\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.58233\n",
            "Epoch 16/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 1.5939 - acc: 0.5429 - val_loss: 1.4464 - val_acc: 0.6306\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.58233 to 1.44638, saving model to model.h5\n",
            "Epoch 17/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 1.5725 - acc: 0.5559 - val_loss: 1.5076 - val_acc: 0.5796\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.44638\n",
            "Epoch 18/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 1.4997 - acc: 0.5729 - val_loss: 1.2765 - val_acc: 0.6911\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.44638 to 1.27650, saving model to model.h5\n",
            "Epoch 19/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 1.3761 - acc: 0.5918 - val_loss: 1.1891 - val_acc: 0.6975\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.27650 to 1.18906, saving model to model.h5\n",
            "Epoch 20/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 1.2781 - acc: 0.6238 - val_loss: 1.1721 - val_acc: 0.6815\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.18906 to 1.17208, saving model to model.h5\n",
            "Epoch 21/100\n",
            "1002/1002 [==============================] - 7s 6ms/step - loss: 1.2745 - acc: 0.6168 - val_loss: 1.0662 - val_acc: 0.7389\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.17208 to 1.06624, saving model to model.h5\n",
            "Epoch 22/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 1.1254 - acc: 0.6607 - val_loss: 0.9598 - val_acc: 0.7452\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.06624 to 0.95977, saving model to model.h5\n",
            "Epoch 23/100\n",
            "1002/1002 [==============================] - 7s 6ms/step - loss: 1.1246 - acc: 0.6527 - val_loss: 0.9207 - val_acc: 0.7420\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.95977 to 0.92069, saving model to model.h5\n",
            "Epoch 24/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.9618 - acc: 0.7026 - val_loss: 0.8043 - val_acc: 0.7962\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.92069 to 0.80434, saving model to model.h5\n",
            "Epoch 25/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.9975 - acc: 0.6906 - val_loss: 0.7837 - val_acc: 0.8217\n",
            "\n",
            "Epoch 00025: val_loss improved from 0.80434 to 0.78366, saving model to model.h5\n",
            "Epoch 26/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.8534 - acc: 0.7236 - val_loss: 0.7951 - val_acc: 0.8089\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.78366\n",
            "Epoch 27/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.8919 - acc: 0.7355 - val_loss: 0.7924 - val_acc: 0.7803\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.78366\n",
            "Epoch 28/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.8646 - acc: 0.7345 - val_loss: 0.6582 - val_acc: 0.8376\n",
            "\n",
            "Epoch 00028: val_loss improved from 0.78366 to 0.65821, saving model to model.h5\n",
            "Epoch 29/100\n",
            "1002/1002 [==============================] - 7s 7ms/step - loss: 0.7890 - acc: 0.7555 - val_loss: 0.8064 - val_acc: 0.7866\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.65821\n",
            "Epoch 30/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.8054 - acc: 0.7335 - val_loss: 0.6348 - val_acc: 0.8376\n",
            "\n",
            "Epoch 00030: val_loss improved from 0.65821 to 0.63478, saving model to model.h5\n",
            "Epoch 31/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.7005 - acc: 0.7735 - val_loss: 0.5853 - val_acc: 0.8439\n",
            "\n",
            "Epoch 00031: val_loss improved from 0.63478 to 0.58534, saving model to model.h5\n",
            "Epoch 32/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.6532 - acc: 0.7884 - val_loss: 0.5825 - val_acc: 0.8631\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.58534 to 0.58253, saving model to model.h5\n",
            "Epoch 33/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.6200 - acc: 0.7994 - val_loss: 0.5530 - val_acc: 0.8535\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.58253 to 0.55302, saving model to model.h5\n",
            "Epoch 34/100\n",
            "1002/1002 [==============================] - 7s 6ms/step - loss: 0.6078 - acc: 0.8024 - val_loss: 0.5372 - val_acc: 0.8344\n",
            "\n",
            "Epoch 00034: val_loss improved from 0.55302 to 0.53720, saving model to model.h5\n",
            "Epoch 35/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.5722 - acc: 0.8054 - val_loss: 0.5562 - val_acc: 0.8503\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.53720\n",
            "Epoch 36/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.5779 - acc: 0.8194 - val_loss: 0.5314 - val_acc: 0.8599\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.53720 to 0.53137, saving model to model.h5\n",
            "Epoch 37/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.5685 - acc: 0.8224 - val_loss: 0.6207 - val_acc: 0.8599\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.53137\n",
            "Epoch 38/100\n",
            "1002/1002 [==============================] - 7s 6ms/step - loss: 0.5853 - acc: 0.8164 - val_loss: 0.4999 - val_acc: 0.8694\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.53137 to 0.49992, saving model to model.h5\n",
            "Epoch 39/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.5283 - acc: 0.8263 - val_loss: 0.4768 - val_acc: 0.8790\n",
            "\n",
            "Epoch 00039: val_loss improved from 0.49992 to 0.47685, saving model to model.h5\n",
            "Epoch 40/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.4681 - acc: 0.8323 - val_loss: 0.4582 - val_acc: 0.8917\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.47685 to 0.45821, saving model to model.h5\n",
            "Epoch 41/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.4795 - acc: 0.8423 - val_loss: 0.4925 - val_acc: 0.8854\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.45821\n",
            "Epoch 42/100\n",
            "1002/1002 [==============================] - 7s 6ms/step - loss: 0.4192 - acc: 0.8633 - val_loss: 0.5623 - val_acc: 0.8854\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.45821\n",
            "Epoch 43/100\n",
            "1002/1002 [==============================] - 7s 6ms/step - loss: 0.4169 - acc: 0.8633 - val_loss: 0.5126 - val_acc: 0.8790\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.45821\n",
            "Epoch 44/100\n",
            "1002/1002 [==============================] - 7s 6ms/step - loss: 0.4319 - acc: 0.8593 - val_loss: 0.3921 - val_acc: 0.8949\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.45821 to 0.39213, saving model to model.h5\n",
            "Epoch 45/100\n",
            "1002/1002 [==============================] - 7s 7ms/step - loss: 0.4727 - acc: 0.8503 - val_loss: 0.4161 - val_acc: 0.8917\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.39213\n",
            "Epoch 46/100\n",
            "1002/1002 [==============================] - 7s 7ms/step - loss: 0.4182 - acc: 0.8613 - val_loss: 0.4259 - val_acc: 0.8917\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.39213\n",
            "Epoch 47/100\n",
            "1002/1002 [==============================] - 7s 7ms/step - loss: 0.3890 - acc: 0.8733 - val_loss: 0.5882 - val_acc: 0.8726\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.39213\n",
            "Epoch 48/100\n",
            "1002/1002 [==============================] - 7s 6ms/step - loss: 0.3372 - acc: 0.8912 - val_loss: 0.4161 - val_acc: 0.8854\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.39213\n",
            "Epoch 49/100\n",
            "1002/1002 [==============================] - 7s 7ms/step - loss: 0.3487 - acc: 0.8842 - val_loss: 0.4704 - val_acc: 0.8885\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.39213\n",
            "Epoch 50/100\n",
            "1002/1002 [==============================] - 7s 7ms/step - loss: 0.3707 - acc: 0.8653 - val_loss: 0.5736 - val_acc: 0.8854\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.39213\n",
            "Epoch 51/100\n",
            "1002/1002 [==============================] - 7s 6ms/step - loss: 0.3594 - acc: 0.8703 - val_loss: 0.5811 - val_acc: 0.8822\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.39213\n",
            "Epoch 52/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.3715 - acc: 0.8743 - val_loss: 0.4069 - val_acc: 0.9045\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.39213\n",
            "Epoch 53/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.3546 - acc: 0.8832 - val_loss: 0.4698 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.39213\n",
            "Epoch 54/100\n",
            "1002/1002 [==============================] - 7s 7ms/step - loss: 0.3647 - acc: 0.8892 - val_loss: 0.5381 - val_acc: 0.8758\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.39213\n",
            "Epoch 55/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.4045 - acc: 0.8653 - val_loss: 0.4871 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.39213\n",
            "Epoch 56/100\n",
            "1002/1002 [==============================] - 7s 6ms/step - loss: 0.3613 - acc: 0.8802 - val_loss: 0.6450 - val_acc: 0.8631\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.39213\n",
            "Epoch 57/100\n",
            "1002/1002 [==============================] - 7s 6ms/step - loss: 0.3162 - acc: 0.8892 - val_loss: 0.5215 - val_acc: 0.8885\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.39213\n",
            "Epoch 58/100\n",
            "1002/1002 [==============================] - 7s 7ms/step - loss: 0.3551 - acc: 0.8772 - val_loss: 0.4258 - val_acc: 0.9045\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.39213\n",
            "Epoch 59/100\n",
            "1002/1002 [==============================] - 7s 7ms/step - loss: 0.3132 - acc: 0.8862 - val_loss: 0.4498 - val_acc: 0.9045\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.39213\n",
            "Epoch 60/100\n",
            "1002/1002 [==============================] - 7s 7ms/step - loss: 0.3094 - acc: 0.9042 - val_loss: 0.4250 - val_acc: 0.8949\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.39213\n",
            "Epoch 61/100\n",
            "1002/1002 [==============================] - 7s 7ms/step - loss: 0.2813 - acc: 0.9162 - val_loss: 0.4434 - val_acc: 0.8949\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.39213\n",
            "Epoch 62/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.3209 - acc: 0.8882 - val_loss: 0.4790 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.39213\n",
            "Epoch 63/100\n",
            "1002/1002 [==============================] - 7s 6ms/step - loss: 0.3219 - acc: 0.8882 - val_loss: 0.5066 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.39213\n",
            "Epoch 64/100\n",
            "1002/1002 [==============================] - 7s 7ms/step - loss: 0.2775 - acc: 0.9002 - val_loss: 0.4067 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.39213\n",
            "Epoch 65/100\n",
            "1002/1002 [==============================] - 7s 6ms/step - loss: 0.2588 - acc: 0.9152 - val_loss: 0.5092 - val_acc: 0.9013\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.39213\n",
            "Epoch 66/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2405 - acc: 0.9202 - val_loss: 0.4210 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.39213\n",
            "Epoch 67/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2801 - acc: 0.8942 - val_loss: 0.3892 - val_acc: 0.9140\n",
            "\n",
            "Epoch 00067: val_loss improved from 0.39213 to 0.38923, saving model to model.h5\n",
            "Epoch 68/100\n",
            "1002/1002 [==============================] - 7s 7ms/step - loss: 0.2624 - acc: 0.9062 - val_loss: 0.4837 - val_acc: 0.9013\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.38923\n",
            "Epoch 69/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2552 - acc: 0.9172 - val_loss: 0.4903 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.38923\n",
            "Epoch 70/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2670 - acc: 0.9152 - val_loss: 0.5260 - val_acc: 0.8917\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.38923\n",
            "Epoch 71/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2614 - acc: 0.9072 - val_loss: 0.5238 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.38923\n",
            "Epoch 72/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2529 - acc: 0.9112 - val_loss: 0.4486 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.38923\n",
            "Epoch 73/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2343 - acc: 0.9202 - val_loss: 0.5621 - val_acc: 0.8917\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.38923\n",
            "Epoch 74/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2526 - acc: 0.9122 - val_loss: 0.6131 - val_acc: 0.8917\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.38923\n",
            "Epoch 75/100\n",
            "1002/1002 [==============================] - 7s 7ms/step - loss: 0.2646 - acc: 0.9092 - val_loss: 0.5864 - val_acc: 0.8885\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.38923\n",
            "Epoch 76/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2253 - acc: 0.9212 - val_loss: 0.6212 - val_acc: 0.8949\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.38923\n",
            "Epoch 77/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2304 - acc: 0.9212 - val_loss: 0.4705 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.38923\n",
            "Epoch 78/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2026 - acc: 0.9261 - val_loss: 0.4552 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.38923\n",
            "Epoch 79/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2304 - acc: 0.9251 - val_loss: 0.4680 - val_acc: 0.9140\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.38923\n",
            "Epoch 80/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2273 - acc: 0.9281 - val_loss: 0.4958 - val_acc: 0.9140\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.38923\n",
            "Epoch 81/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2227 - acc: 0.9281 - val_loss: 0.4398 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.38923\n",
            "Epoch 82/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2107 - acc: 0.9341 - val_loss: 0.5246 - val_acc: 0.9236\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.38923\n",
            "Epoch 83/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2333 - acc: 0.9182 - val_loss: 0.6698 - val_acc: 0.8758\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.38923\n",
            "Epoch 84/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2350 - acc: 0.9152 - val_loss: 0.4395 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.38923\n",
            "Epoch 85/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2686 - acc: 0.9042 - val_loss: 0.4677 - val_acc: 0.9013\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.38923\n",
            "Epoch 86/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2068 - acc: 0.9291 - val_loss: 0.4818 - val_acc: 0.9045\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.38923\n",
            "Epoch 87/100\n",
            "1002/1002 [==============================] - 7s 7ms/step - loss: 0.1938 - acc: 0.9381 - val_loss: 0.5059 - val_acc: 0.8981\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.38923\n",
            "Epoch 88/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.1938 - acc: 0.9251 - val_loss: 0.4771 - val_acc: 0.9076\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.38923\n",
            "Epoch 89/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.1853 - acc: 0.9341 - val_loss: 0.4421 - val_acc: 0.9045\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.38923\n",
            "Epoch 90/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2038 - acc: 0.9251 - val_loss: 0.4420 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.38923\n",
            "Epoch 91/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2181 - acc: 0.9321 - val_loss: 0.5740 - val_acc: 0.8917\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.38923\n",
            "Epoch 92/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.1760 - acc: 0.9401 - val_loss: 0.4564 - val_acc: 0.9172\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.38923\n",
            "Epoch 93/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.1888 - acc: 0.9311 - val_loss: 0.5552 - val_acc: 0.9108\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.38923\n",
            "Epoch 94/100\n",
            "1002/1002 [==============================] - 7s 6ms/step - loss: 0.1686 - acc: 0.9401 - val_loss: 0.4511 - val_acc: 0.9204\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.38923\n",
            "Epoch 95/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.1956 - acc: 0.9381 - val_loss: 0.5816 - val_acc: 0.9045\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.38923\n",
            "Epoch 96/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2084 - acc: 0.9271 - val_loss: 0.9508 - val_acc: 0.8662\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.38923\n",
            "Epoch 97/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.4540 - acc: 0.8673 - val_loss: 0.7535 - val_acc: 0.8312\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.38923\n",
            "Epoch 98/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.4500 - acc: 0.8663 - val_loss: 0.4839 - val_acc: 0.8917\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.38923\n",
            "Epoch 99/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.3339 - acc: 0.8872 - val_loss: 0.5791 - val_acc: 0.8949\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.38923\n",
            "Epoch 100/100\n",
            "1002/1002 [==============================] - 6s 6ms/step - loss: 0.2210 - acc: 0.9162 - val_loss: 0.5478 - val_acc: 0.9013\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.38923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIL1xGl0iUQD"
      },
      "source": [
        " model = load_model(\"model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9KN2N6viaWQ"
      },
      "source": [
        "def predictions(text):\n",
        "  \n",
        "  test_word = word_tokenize(text)\n",
        "  test_ls = word_tokenizer.texts_to_sequences(test_word)\n",
        "  print(test_word)\n",
        "  #Check for unknown words\n",
        "  if [] in test_ls:\n",
        "    test_ls = list(filter(None, test_ls))\n",
        "    \n",
        "  test_ls = np.array(test_ls).reshape(1, len(test_ls))\n",
        " \n",
        "  x = padding_doc(test_ls, max_length)\n",
        "  \n",
        "  pred = model.predict_proba(x)\n",
        "  \n",
        "  \n",
        "  return pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtGPJJ0toZDh"
      },
      "source": [
        "def get_final_output(pred, classes):\n",
        "  predictions = pred[0]\n",
        " \n",
        "  classes = np.array(classes)\n",
        "  ids = np.argsort(-predictions)\n",
        "  classes = classes[ids]\n",
        "  predictions = -np.sort(-predictions)\n",
        " \n",
        "  for i in range(pred.shape[1]):\n",
        "    print(\"%s has confidence = %s\" % (classes[i], (predictions[i])))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cdnd-hUeodU_",
        "outputId": "68a0a40a-d6e8-4f69-f2de-2b1d8460b09f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "text = \"எனது கடன்அட்டையை நான் எவ்வகையில் ரத்து செய்வது?\"\n",
        "pred = predictions(text)\n",
        "get_final_output(pred, unique_intent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['எனது', 'கடன்அட்டையை', 'நான்', 'எவ்வகையில்', 'ரத்து', 'செய்வது', '?']\n",
            "cancel_card has confidence = 0.21924439\n",
            "update_personal_details has confidence = 0.12690732\n",
            "resident_foreign_account_info has confidence = 0.10434062\n",
            "change_details has confidence = 0.089567006\n",
            "SLBFE_info has confidence = 0.086473614\n",
            "tikiri_gift_voucher_validity has confidence = 0.07680813\n",
            "tikiri_gift_voucher_per_person has confidence = 0.07067075\n",
            "2in1_acoount_info has confidence = 0.058321506\n",
            "marriage_claim has confidence = 0.027570482\n",
            "NRFC_info has confidence = 0.020597674\n",
            "joint_account_details has confidence = 0.020425798\n",
            "selan_sure_info has confidence = 0.019626223\n",
            "get_lc_form has confidence = 0.010514114\n",
            "2in1_min_balance has confidence = 0.010053273\n",
            "seylan_tikiri_minimum_deposit has confidence = 0.008476666\n",
            "tikiri_gift_voucher_redeem has confidence = 0.005339367\n",
            "treasury_bond_advantage has confidence = 0.004835874\n",
            "CVV_use has confidence = 0.0029916826\n",
            "suspious_activity has confidence = 0.002957841\n",
            "debit_card_requirement has confidence = 0.0025749046\n",
            "tikiri_gift_voucher_min_amount has confidence = 0.0025148792\n",
            "treasury_bond_information has confidence = 0.0025112208\n",
            "card_usage has confidence = 0.0022300992\n",
            "get_monthly_report has confidence = 0.00211315\n",
            "loan_requirement has confidence = 0.0020357103\n",
            "tikiri_gift_voucher_age_limit has confidence = 0.0020306834\n",
            "tikiri_gift_voucher_info has confidence = 0.0019111967\n",
            "tikiri_gift_voucher_withdrawal has confidence = 0.0017125177\n",
            "account_currency has confidence = 0.0015288058\n",
            "NRFC_account_opening has confidence = 0.0014690083\n",
            "bank_statement_online has confidence = 0.0012619013\n",
            "repos_benefits has confidence = 0.0010872068\n",
            "tikiri_required_docs has confidence = 0.0010836706\n",
            "interest_credit_info has confidence = 0.00089825736\n",
            "foreign_currency_withdrawal has confidence = 0.00083057606\n",
            "foreign_account_lkr_withdrawal has confidence = 0.0007789336\n",
            "card_foreign_use has confidence = 0.0007023324\n",
            "life_insurance_limit has confidence = 0.0006451179\n",
            "card_automatic_renewal has confidence = 0.00047149174\n",
            "saving_atmcard_available has confidence = 0.00041265754\n",
            "housing_loan_purpose has confidence = 0.0004109194\n",
            "new_saving_book has confidence = 0.00036518884\n",
            "tikiri_gift_voucher_buying_info has confidence = 0.00036317913\n",
            "card_machine_repair has confidence = 0.00035118245\n",
            "foreign_currency_withdrawal_currency has confidence = 0.0002774571\n",
            "2in1_interest_receiving has confidence = 0.00027550303\n",
            "internet_bank_loan_amount has confidence = 0.0002619742\n",
            "2in1_pass_book has confidence = 0.0002578175\n",
            "sl_development_bond_benefits has confidence = 0.0001923867\n",
            "precashing_foreign_fixed_deposit has confidence = 0.00014852143\n",
            "housing_loan_documents has confidence = 0.00014180248\n",
            "treasury_bond_important_features has confidence = 0.00013895305\n",
            "new_card_reader_cost has confidence = 0.000106223175\n",
            "2in1_atm_card has confidence = 7.608373e-05\n",
            "foreign_deposit_loan has confidence = 7.0871625e-05\n",
            "FCAISPE_required_docs has confidence = 3.5285055e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApOOs_cxsu1f",
        "outputId": "26785f23-98e5-4beb-a58e-f5a4388f6069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "print(model.test_on_batch(test_X ,test_Y))\n",
        "model.metrics_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.36097506, 0.936255]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['loss', 'acc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    }
  ]
}