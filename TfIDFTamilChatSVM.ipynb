{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TfIDFTamilChatSVM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMGdnIxJ9hYY1QQt/V5Vxge"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMGdVhNx6Yw2",
        "outputId": "f1a5fc57-798c-43f0-b590-f57b9aad8847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_list = []\n",
        "filepath ='/content/bank.csv'\n",
        "df = pd.read_csv(filepath, encoding = \"utf-8\", names=['sentence', 'label'], sep=',')\n",
        "df_list.append(df)\n",
        "\n",
        "df = pd.concat(df_list)\n",
        "print(df.iloc[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence    நான் 2in1 கணக்கில் சேமிப்பது எப்படி ?\n",
            "label                           2in1_acoount_info\n",
            "Name: 0, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-svpcUH9QFh",
        "outputId": "2d3dc8a4-0e12-4049-bd97-d7b538663273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "sentences = df['sentence'].values\n",
        "y = df['label'].values\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnwPRkKoup9I",
        "outputId": "6723873e-aa05-4157-c3a6-cb03f3f28530",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.30, stratify=y)\n",
        "print(sentences_train[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "திறைசேரி உண்டியல்கள் மற்றும் பத்திரங்களை முதலீடு செய்வது எப்படி?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA1Se2XKu1fa",
        "outputId": "a11aaf27-58d0-4ebf-d7fe-17f35a0a3ad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#vectorizer = CountVectorizer(encoding='utf-8', tokenizer=nltk.word_tokenize)\n",
        "\n",
        "vectorizer = CountVectorizer(encoding='utf-8', tokenizer=nltk.word_tokenize, stop_words = frozenset([\",\" , \".\", \"?\",\"ஒரு\",\"என்று\",\"மற்றும்\",\"இந்த\",\"இது\",\"என்ற\",\"கொண்டு\",\"என்பது\",\"பல\",\"ஆகும்\",\"அல்லது\",\"அவர்\",\"நான்\",\"உள்ள\",\"அந்த\",\"இவர்\",\"என\",\"முதல்\",\"என்ன\",\"இருந்து\",\"சில\",\"என்\",\"போன்ற\",\"வேண்டும்\",\"வந்து\",\"இதன்\",\"அது\",\"அவன்\",\"தான்\",\"பலரும்\",\"என்னும்\",\"மேலும்\",\"பின்னர்\",\"கொண்ட\",\"இருக்கும்\",\"தனது\",\"உள்ளது\",\"போது\",\"என்றும்\",\"அதன்\",\"தன்\",\"பிறகு\",\"அவர்கள்\",\"வரை\",\"அவள்\",\"நீ\",\"ஆகிய\",\"இருந்தது\",\"உள்ளன\",\"வந்த\",\"இருந்த\",\"மிகவும்\",\"இங்கு\",\"மீது\",\"ஓர்\",\"இவை\",\"இந்தக்\",\"பற்றி\",\"வரும்\",\"வேறு\",\"இரு\",\"இதில்\",\"போல்\",\"இப்போது\",\"அவரது\",\"மட்டும்\",\"இந்தப்\",\"எனும்\",\"மேல்\",\"பின்\",\"சேர்ந்த\",\"ஆகியோர்\",\"எனக்கு\",\"இன்னும்\",\"அந்தப்\",\"அன்று\",\"ஒரே\",\"மிக\",\"அங்கு\",\"பல்வேறு\",\"விட்டு\",\"பெரும்\",\"அதை\",\"பற்றிய\",\"உன்\",\"அதிக\",\"அந்தக்\",\"பேர்\",\"இதனால்\",\"அவை\",\"அதே\",\"ஏன்\",\"முறை\",\"யார்\",\"என்பதை\",\"எல்லாம்\",\"மட்டுமே\",\"இங்கே\",\"அங்கே\",\"இடம்\",\"இடத்தில்\",\"அதில்\",\"நாம்\",\"அதற்கு\",\"எனவே\",\"பிற\",\"சிறு\",\"மற்ற\",\"விட\",\"எந்த\",\"எனவும்\",\"எனப்படும்\",\"எனினும்\",\"அடுத்த\",\"இதனை\",\"இதை\",\"கொள்ள\",\"இந்தத்\",\"இதற்கு\",\"அதனால்\",\"தவிர\",\"போல\",\"வரையில்\"]))\n",
        "\n",
        "\n",
        "vectorizer.fit(sentences_train)\n",
        "\n",
        "X_train = vectorizer.transform(sentences_train)\n",
        "X_test  = vectorizer.transform(sentences_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkKS3p55aCBc"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train)\n",
        "X_train_tfidf.shape\n",
        "X_test1 = tfidf_transformer.fit_transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jKiy9ytGdDn",
        "outputId": "a3739d74-0652-4b96-cac1-46a5fa50b65c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn import svm\n",
        "C = 1.0 # SVM regularization parameter\n",
        "\n",
        "classifierSVM = svm.SVC(kernel='linear', C=1,gamma=1)\n",
        "classifierSVM .fit(X_train_tfidf, y_train)\n",
        "score = classifierSVM.score(X_test1, y_test)\n",
        "print(score)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9915074309978769\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWPRR90laeQk",
        "outputId": "8ceccb9e-3db2-40aa-84f5-9c8c6aa0183b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "predicted = classifier.predict(X_test1)\n",
        "np.mean(predicted == y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9915074309978769"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTVl8KlLcwvu",
        "outputId": "0034b44a-7693-4d71-e3f0-ac0969cac13f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "C = 1.0 # SVM regularization parameter\n",
        "\n",
        "classifierSVM1 = svm.SVC(kernel='linear', C=1,gamma=1)\n",
        "classifierSVM1.fit(X_train, y_train)\n",
        "score = classifierSVM1.score(X_test, y_test)\n",
        "print(score)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9787685774946921\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}